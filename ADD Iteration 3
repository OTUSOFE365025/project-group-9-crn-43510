ADD Iteration 3— 7 ADD Steps

1. Review Input
2. Establish Iteration Goal by Selecting Drivers
3. Choose System Elements to Decompose
4. Choose Design Concepts to Satisfy Drivers
5. Instantiate Subcomponents and Define Interfaces
6. Sketch Views and Record Design Decisions
7. Analyze the Design Against the Iteration Goal

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------

### Step 1 — Review Input

We revisted the requirements with emphasis on the quality attributes, focusing on scalability under load, reliability for critical operations,
and auditability for data actions.

### Step 2 — Establish Iteration Goal by Selecting Drivers

This iteration targets quality attributes to refine the previously outlined subsystems, ensuring that the system supports associated use cases.

### Step 3 — Choose System Elements to Decompose
| Subsystem/Component                                   | Reason for Further Decomposition                                                                 | Addressed QAs |
|-------------------------------------------------------|----------------------------------------------------------------------------------------------------------|---------------|
| **NLU / AI Subsystem (Cache Layer & Model Server)**  | Scaling for high-volume queries and inference to meet performance and scalability needs                | QA1, QA8      |
| **Integration Subsystem (Retry Queue & Error Handler)** | Handling API spikes reliably without failures, ensuring availability and interoperability           | QA4, QA5, QA7 |
| **User Profile & Personalization (Profile Store & History Manager)** | Secure, auditable storage with compliance features for growing data                             | QA12, QA13    |
| **Notification Subsystem (Message Queue & Event Scheduler)** | Load-balanced delivery for reliability and maintainability during peaks                          | QA4, QA5, QA6 |


### Step 4 — Choose Design Concepts to Satisfy Drivers

Concepts chosen to address QAs:
  - Auto scaling and sharding for scalability/performance (QA8,QA1)
  - Redundancy, failover, and circuit breakers for reliability/availability (QA4, QA5)
  - Comprehensive logging and audit trails for auditability (QA12)
  - Encryption, data governance, and export mechanisms for compliance (QA13)
  - Blue-green deployments and monitoring for maintainability (QA6)

### Step 5 — Instantiate Subcomponents & Define Interfaces

  #### 5.1 NLU/AI Subsystem
| Internal Subcomponent | Description                                            | Addressed QAs |
|-----------------------|--------------------------------------------------------|---------------|
| Distributed Cache     | Sharded cache (e.g., Redis) for scalable query handling | QA1, QA8      |
| Inference Engine      | Auto-scaling inference with load monitoring           | QA1, QA8      |
| Model Registry        | Manages versions for easy updates                      | QA6           |
| Audit Logger          | Logs all model accesses and changes                    | QA12          |

  #### 5.2 Integration Subsystem
| Subcomponent       | Description                                 | Addressed QAs |
|--------------------|---------------------------------------------|---------------|
| Circuit Breaker    | Halts calls to failing APIs                 | QA4, QA5      |
| Rate Limiter       | Manages call frequency for scalability     | QA8           |
| Failover Router    | Routes to backups for availability          | QA5           |
| Compliance Checker | Validates data sync per policies            | QA13          |
 
  #### 5.3 User Profile and Personalization
| Subcomponent      | Description                                                  | Addressed QAs |
|-------------------|--------------------------------------------------------------|---------------|
| Encrypted Store   | Encrypted database with sharding                             | QA13, QA8     |
| Access Auditor    | Logs user data actions (User ID, time, action, resource)    | QA12          |
| Data Exporter     | Handles user requests for data review/export/deletion        | QA13          |
| Update Deployer   | Supports zero-downtime profile updates                       | QA6           |
 
  #### 5.4 - Notification Subsystem
| Subcomponent     | Description                                          | Addressed QAs |
|------------------|------------------------------------------------------|---------------|
| Queue Cluster    | Redundant queues for reliability                     | QA4, QA5      |
| Load Balancer    | Distributes tasks for scalability                    | QA8           |
| Audit Trail      | Logs all notification actions                        | QA12          |
| Policy Enforcer  | Ensures ethical/policy compliance in dispatches      | QA13          |

### Step 6 — Sketch Views & Record Design Decisions

| Design Decision                                      | Intended Quality Attribute(s)          | Explanation                                                                                                       |
|------------------------------------------------------|----------------------------------------|-------------------------------------------------------------------------------------------------------------------|
| Sharding and Auto-Scaling in NLU/AI                  | Scalability, Performance              | Supports concurrent users and quick responses; requires consistency management                                   |
| Failover and Circuit Breakers in Integrations        | Reliability, Availability             | Ensures data sync and uptime during failures; adds configuration complexity                                       |
| Audit Logs and Access Auditors in Profiles           | Auditability                           | Records all actions for observability; balances with storage needs                                               |
| Encryption, Exporters, and Policy Checks             | Compliance                             | Meets legal/data handling requirements; may impact performance slightly                                         |
| Blue-Green Deployments and Monitoring                | Maintainability                        | Allows updates without downtime; facilitates monitoring for ongoing improvements                                 |
| Queue Clustering and Load Balancing in Notifications | Reliability, Availability, Scalability| Handles peaks reliably; prevents delays in announcements, with backlog monitoring needed                        |
 

### Step 7 — Analyze the Design Against the Iteration Goal

  #### 7.1 ATAM Utility Tree

##### Utility

  ##### Performance
    -Latency
      Scenario: User queries NLU for intent classification during peak hours (stimulus: 1000 concurrent requests; environment: normal operation; response: processes within bounds; measure: 95% under 500ms).

    -Throughput
      Scenario: Notification subsystem handles bulk announcements (stimulus: 10,000 notifications/min; environment: high load; response: delivers without loss; measure: 99.9% success rate).


  ##### Security
    -Data Protection
      Scenario: Unauthorized access attempt to user profiles (stimulus: invalid credentials; environment: production; response: denies access and logs; measure: 100% detection and audit).

    -Privacy Compliance
      Scenario: Data export for GDPR request (stimulus: user request; environment: normal; response: provides encrypted export; measure: within 72 hours).


  ##### Reliability
    -Availability
      Scenario: External API outage (stimulus: LMS down for 30min; environment: integration failure; response: retries and fails over; measure: system uptime >99.5%).

    -Fault Tolerance
      Scenario: Queue overload in notifications (stimulus: sudden spike; environment: peak; response: scales and recovers; measure: no data loss).


  ##### Modifiability
    -Ease of Updates
      Scenario: Deploy new AI model version (stimulus: update request; environment: staging to prod; response: deploys without downtime; measure: under 5min).

    -Extensibility
      Scenario: Add new integration adapter (stimulus: new API; environment: development; response: integrates seamlessly; measure: <1 day effort).


  ##### Usability
    -Personalization
      Scenario: User switches language mid-conversation (stimulus: preference change; environment: ongoing session; response: adapts responses; measure: seamless transition).

    -Accessibility
      Scenario: Multi-device access to dashboard (stimulus: mobile/desktop switch; environment: normal; response: consistent UI; measure: 100% feature parity).
  
  #### 7.2 ATAM Risk Assessment

| Risk ID | Risk Description                                                                 | Sensitivity Point             | Tradeoff Point                                      | Mitigation Strategy                                      | Priority |
|---------|----------------------------------------------------------------------------------|-------------------------------|-----------------------------------------------------|----------------------------------------------------------|----------|
| R1      | Scalability limits in NLU caching during extreme loads could cause latency spikes | Cache sharding configuration  | Performance vs. Complexity (more shards increase management overhead) | Implement auto-scaling and stress testing                | High     |
| R2      | Integration failures from unreliable external APIs might propagate despite circuit breakers | Retry queue thresholds        | Reliability vs. Cost (more retries increase API usage fees) | Add adaptive backoff and monitoring alerts               | Medium   |
| R3      | Data encryption in profiles reduces query speed, impacting usability            | Encryption algorithm choice   | Security vs. Performance (stronger encryption slows access) | Use hardware-accelerated encryption and indexing        | High     |
| R4      | Notification queue clustering could lead to consistency issues in distributed setups | Queue partitioning            | Reliability vs. Maintainability (complex syncing)   | Employ eventual consistency with idempotent operations   | Medium   |
| R5      | Lack of comprehensive logging might hinder compliance audits                    | Audit logger granularity      | Compliance vs. Storage (detailed logs consume space) | Implement log rotation and selective logging             | Low      |
| R6      | Model updates in AI could introduce backward-incompatible changes               | Versioning strategy           | Modifiability vs. Stability (frequent updates risk regressions) | Enforce API contracts and automated regression tests    | High     |

